# Deep-RL-for-mobile-robots

En el archivo "__init__.py" hay que añadir el entorno creado (ver últimas líneas).

En el archivo "mujoco/__init__.py" se immporta el entorno en concreto (ver útlima línea).

El archivo "mujoco/rover.py" contiene la definición del entorno: inicialización, función de recompensa, observaciones...

"entorno.yml" contiene todas las dependencias y librerías necesarias del entorno de conda empleado para la ejecución de las simulaciones.

En RL_PRUEBAS están las carpetas del LunarLander, el Reacher y el MuSHR con sus respectivos códigos de entrenamiento y ejecución de un modelo concreto. Además se añaden los entrenamientos que he podido llevar a cabo con mi ordenador con cada uno de los entornos.

Además se encuentra la memoria del TFG actual.